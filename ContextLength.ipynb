{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Length Experiment\n",
    "\n",
    "This notebook is to experiment how well ultra-long context LLMs can perform reasoning tasks over their context length. \n",
    "\n",
    "## Observation\n",
    "\n",
    "Needle-in-a-haystack (NIH) tests test the ability of the LLM to find factoids that have been sprinkled randomly into the context. For example they might put things like \"Pineapple is the best pizza topping\" somewhere in all of the Paul Graham essays, then ask the LLM what is the best pizza topping. This is great for measuring how well the LLM can recall facts from its context but it doesnt measure how well the LLM can reason over 1M tokens of context.\n",
    "\n",
    "This experiment will test that ability. We will fill the context window up gradually and measure how well the LLM can answer questions that require it to understand the entire context. \n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "My guess is that the agent will be able to perform these tasks with high accuracy in low context lengths, and the accuracy will drop off after a point. I also believe that the LLM will be close to accurate every time, but will not be 100% accurate after a certain threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "The way we will be able to evaluate the accuracy is by choosing tasks that we can validate programattically. So we cant just ask it for an analysis because we wont be able to descreetly validate the analysis results. We also want to avoid adding variables, so we won't want to include any tests that guage the ability of the LLM to count or function call for example. So in that case I thought of a few experiments:\n",
    "\n",
    "1. Parse Titles - We ask the LLM to give us a list of all of the titles of all of the essays in order. We can write some regex scripts to parse that info ourselves and validate precision and recall and order correctness.\n",
    "2. Parse Quotes - We ask the LLM to give us a list of all of the quotes that Paul Graham includes in his essays. We can then write regex to parse out everything wrapped in quotes (or `blockquotes`) and validate precision and recall\n",
    "3. Ordered Instructions - We write a set of step by step instructions and break those steps up and sprinkle them randomly in the essays in order. We then ask the LLM to put those instructions together into the correct order and validate the accuracy.\n",
    "4. Unordered Instructions - Same as the previous experiment but mix the order of the steps.\n",
    "5. Parse Links - Parse out all of the href links from the essays and validate the accuracy of the LLM in parsing out the links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def split_essays():\n",
    "    \"\"\"Split the Paul Graham essays\"\"\"\n",
    "    with open(\"./paul_graham_essay.txt\", \"r\") as file:\n",
    "        essay_text = file.read()\n",
    "\n",
    "    essays = []\n",
    "    lines = []\n",
    "    # Regex to match titles formatted as \"Month Year\"\n",
    "    title_pattern = re.compile(r'^(January|February|March|April|May|June|July|August|September|October|November|December) \\d{4}$')\n",
    "\n",
    "    for line in essay_text.split('\\n'):\n",
    "        if title_pattern.match(line.strip()):\n",
    "            # If we find a title and have collected lines for an essay, save the essay\n",
    "            if lines:\n",
    "                essays.append(\"\\n\".join(lines).strip())\n",
    "                lines = []\n",
    "        lines.append(line)\n",
    "\n",
    "    # Add the last essay collected, if any\n",
    "    if lines:\n",
    "        essays.append(\"\\n\".join(lines).strip())\n",
    "\n",
    "    return essays\n",
    "\n",
    "essays = split_essays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April 2001\n",
      "\n",
      "This essay developed out of conversations I've had with\n",
      "several other programmers about why Java smelled suspicious.  It's not\n",
      "a critique of Java!  It is a case study of hacker's radar.\n",
      "\n",
      "Over time, hackers develop a nose for good (and bad) technology.\n",
      "I thought it might be interesting to try and write down what\n",
      "made Java seem suspect to me.\n",
      "\n",
      "Some people who've read this think it's an interesting attempt to write about\n",
      "something that hasn't been written about before.  Others say I\n",
      "will get in trouble for appearing to be writing about\n",
      "things I don't understand.  So, just in\n",
      "case it does any good, let me clarify that I'm not writing here\n",
      "about Java (which I have never used) but about hacker's radar\n",
      "(which I have thought about a lot).\n",
      "\n",
      "<hr>\n",
      "\n",
      "The aphorism \"you can't tell a book by its cover\" originated in\n",
      "the times when books were sold in plain cardboard covers, to be\n",
      "bound by each purchaser according to his own taste.  In those days,\n",
      "you couldn't tell a book by its cover.  But publishing has advanced\n",
      "since then: present-day publishers work hard to make the cover\n",
      "something you can tell a book by.\n",
      "\n",
      "I spend a lot of time in bookshops and I feel as if I have by now\n",
      "learned to understand everything publishers mean to tell me about\n",
      "a book, and perhaps a bit more.  The time I haven't spent in\n",
      "bookshops I've spent mostly in front of computers, and I feel as\n",
      "if I've learned, to some degree, to judge technology by its cover\n",
      "as well.  It may be just luck, but I've saved myself from a few\n",
      "technologies that turned out to be real stinkers.\n",
      "\n",
      "So far, Java seems like a stinker to me.  I've never written a Java\n",
      "program, never more than glanced over reference books about it,\n",
      "but I have a hunch that it won't be a very successful language.\n",
      "I may turn out to be mistaken; making predictions about technology\n",
      "is a dangerous business.  But for what it's worth, as a sort of\n",
      "time capsule, here's why I don't like the look of Java:\n",
      "\n",
      "\n",
      "1. It has been so energetically hyped.  Real standards don't have\n",
      "to be promoted.  No one had to promote C, or Unix, or HTML.  A real\n",
      "standard tends to be already established by the time most people\n",
      "hear about it.  On the hacker radar screen, Perl is as big as Java,\n",
      "or bigger, just on the strength of its own merits.\n",
      "\n",
      "2. It's aimed low.  In the original Java white paper, Gosling\n",
      "explicitly says Java was designed not to be too difficult for\n",
      "programmers used to C.  It was designed to be another C++: C plus\n",
      "a few ideas taken from more advanced languages.  Like the creators\n",
      "of sitcoms or junk food or package tours, Java's designers were\n",
      "consciously designing a product for people not as smart as them.\n",
      "Historically, languages designed for other people to use have been\n",
      "bad:  Cobol, PL/I, Pascal, Ada, C++.  The good languages have been\n",
      "those that were designed for their own creators:  C, Perl, Smalltalk,\n",
      "Lisp.\n",
      "\n",
      "3. It has ulterior motives.  Someone once said that the world would\n",
      "be a better place if people only wrote books because they had\n",
      "something to say, rather than because they wanted to write a book.\n",
      "Likewise, the reason we hear about Java all the time is not because\n",
      "it has something to say about programming languages.  We hear about\n",
      "Java as part of a plan by Sun to undermine Microsoft.\n",
      "\n",
      "4. No one loves it.  C, Perl, Python, Smalltalk, and Lisp programmers\n",
      "love their languages.  I've never heard anyone say that they loved\n",
      "Java.\n",
      "\n",
      "5. People are forced to use it.  A lot of the people I know using\n",
      "Java are using it because they feel they have to.  Either it's\n",
      "something they felt they had to do to get funded, or something they\n",
      "thought customers would want, or something they were told to do by\n",
      "management.  These are smart people; if the technology was good,\n",
      "they'd have used it voluntarily.\n",
      "\n",
      "6. It has too many cooks.  The best programming languages have been\n",
      "developed by small groups.  Java seems to be run by a committee.\n",
      "If it turns out to be a good language, it will be the first time\n",
      "in history that a committee has designed a good language.\n",
      "\n",
      "7. It's bureaucratic.  From what little I know about Java, there\n",
      "seem to be a lot of protocols for doing things.  Really good\n",
      "languages aren't like that.  They let you do what you want and get\n",
      "out of the way.\n",
      "\n",
      "8. It's pseudo-hip.  Sun now pretends that Java is a grassroots,\n",
      "open-source language effort like Perl or Python.  This one just\n",
      "happens to be controlled by a giant company.  So the language is\n",
      "likely to have the same drab clunkiness as anything else that comes\n",
      "out of a big company.\n",
      "\n",
      "9. It's designed for large organizations.  Large organizations have\n",
      "different aims from hackers. They want languages that are (believed\n",
      "to be) suitable for use by large teams of mediocre programmers--\n",
      "languages with features that, like the speed limiters in U-Haul\n",
      "trucks, prevent fools from doing too much damage.  Hackers don't\n",
      "like a language that talks down to them.  Hackers just want power.\n",
      "Historically, languages designed for large organizations (PL/I,\n",
      "Ada) have lost, while hacker languages (C, Perl) have won.  The\n",
      "reason: today's teenage hacker is tomorrow's CTO.\n",
      "\n",
      "10. The wrong people like it.  The programmers I admire most are\n",
      "not, on the whole, captivated by Java.  Who does like Java?  Suits,\n",
      "who don't know one language from another, but know that they keep\n",
      "hearing about Java in the press; programmers at big companies, who\n",
      "are amazed to find that there is something even better than C++;\n",
      "and plug-and-chug undergrads, who are ready to like anything that\n",
      "might get them a job (will this be on the test?).  These people's\n",
      "opinions change with every wind.\n",
      "\n",
      "11. Its daddy is in a pinch.  Sun's business model is being undermined\n",
      "on two fronts.  Cheap Intel processors, of the same type used in\n",
      "desktop machines, are now more than fast enough for servers.  And\n",
      "FreeBSD seems to be at least as good an OS for servers as Solaris.\n",
      "Sun's advertising implies that you need Sun servers for industrial\n",
      "strength applications.  If this were true, Yahoo would be first in\n",
      "line to buy Suns;  but when I worked there, the servers were all\n",
      "Intel boxes running FreeBSD.  This bodes ill for Sun's future.  If\n",
      "Sun runs into trouble, they could drag Java down with them.\n",
      "\n",
      "12. The DoD likes it.  The Defense Department is encouraging\n",
      "developers to use Java. This seems to me the most damning sign of\n",
      "all.  The Defense Department does a fine (though expensive) job of\n",
      "defending the country, but they love plans and procedures and\n",
      "protocols.  Their culture is the opposite of hacker culture; on\n",
      "questions of software they will tend to bet wrong.  The last time\n",
      "the DoD really liked a programming language, it was Ada.\n",
      "\n",
      "\n",
      "Bear in mind, this is not a critique of Java, but a critique of\n",
      "its cover.  I don't know Java well enough to like it or dislike\n",
      "it.  This is just an explanation of why I don't find that I'm eager\n",
      "to learn it.\n",
      "\n",
      "It may seem cavalier to dismiss a language before you've even tried\n",
      "writing programs in it.  But this is something all programmers have\n",
      "to do.  There are too many technologies out there to learn them\n",
      "all.  You have to learn to judge by outward signs which will be\n",
      "worth your time.  I have likewise cavalierly dismissed Cobol, Ada,\n",
      "Visual Basic, the IBM AS400, VRML, ISO 9000, the SET protocol, VMS,\n",
      "Novell Netware, and CORBA, among others.  They just smelled wrong.\n",
      "\n",
      "It could be that in Java's case I'm mistaken.  It could be that a\n",
      "language promoted by one big company to undermine another, designed\n",
      "by a committee for a \"mainstream\" audience, hyped to the skies,\n",
      "and beloved of the DoD, happens nonetheless to be a clean, beautiful,\n",
      "powerful language that I would love programming in.  It could be,\n",
      "but it seems very unlikely.\n",
      "<table width=100% cellspacing=0>\n",
      "<tr><td bgcolor=#ff9922><img src=\"http://www.virtumundo.com/images/spacer.gif\"\n",
      "height=15 width=1><font size=2>\n",
      "<b>Want to start a startup?</b>  Get funded by\n",
      "<a href=\"http://ycombinator.com/apply.html\">Y Combinator</a>.\n",
      "</font>\n",
      "\n",
      "<img src=\"http://www.virtumundo.com/images/spacer.gif\" height=5 width=1></td\n",
      "></tr>\n",
      "</table>\n",
      "<p>\n",
      "April 2001, rev. April 2003\n",
      "\n",
      "<i>(This article is derived from a talk given at the 2001 Franz\n",
      "Developer Symposium.)\n",
      "</i>\n",
      "\n",
      "In the summer of 1995, my friend Robert Morris and I\n",
      "started a startup called \n",
      "<a href=\"http://docs.yahoo.com/docs/pr/release184.html\">Viaweb</a>.  \n",
      "Our plan was to write\n",
      "software that would let end users build online stores.\n",
      "What was novel about this software, at the time, was\n",
      "that it ran on our server, using ordinary Web pages\n",
      "as the interface.\n",
      "\n",
      "A lot of people could have been having this idea at the\n",
      "same time, of course, but as far as I know, Viaweb was\n",
      "the first Web-based application.  It seemed such\n",
      "a novel idea to us that we named the company after it:\n",
      "Viaweb, because our software worked via the Web,\n",
      "instead of running on your desktop computer.\n",
      "\n",
      "Another unusual thing about this software was that it\n",
      "was written primarily in a programming language called\n",
      "Lisp. It was one of the first big end-user\n",
      "applications to be written in Lisp, which up till then\n",
      "had been used mostly in universities and research labs. [1]\n",
      "\n",
      "<b>The Secret Weapon</b>\n",
      "\n",
      "Eric Raymond has written an essay called \"How to Become a Hacker,\"\n",
      "and in it, among other things, he tells would-be hackers what\n",
      "languages they should learn.  He suggests starting with Python and\n",
      "Java, because they are easy to learn.  The serious hacker will also\n",
      "want to learn C, in order to hack Unix, and Perl for system\n",
      "administration and cgi scripts.  Finally, the truly serious hacker\n",
      "should consider learning Lisp:\n",
      "<blockquote>\n",
      "  Lisp is worth learning for the profound enlightenment experience\n",
      "  you will have when you finally get it; that experience will make\n",
      "  you a better programmer for the rest of your days, even if you\n",
      "  never actually use Lisp itself a lot.\n",
      "</blockquote>\n",
      "This is the same argument you tend to hear for learning Latin.  It\n",
      "won't get you a job, except perhaps as a classics professor, but\n",
      "it will improve your mind, and make you a better writer in languages\n",
      "you do want to use, like English.\n",
      "\n",
      "But wait a minute.  This metaphor doesn't stretch that far.  The\n",
      "reason Latin won't get you a job is that no one speaks it.  If you\n",
      "write in Latin, no one can understand you.  But Lisp is a computer\n",
      "language, and computers speak whatever language you, the programmer,\n",
      "tell them to.\n",
      "\n",
      "So if Lisp makes you a better programmer, like he says, why wouldn't\n",
      "you want to use it? If a painter were offered a brush that would\n",
      "make him a better painter, it seems to me that he would want to\n",
      "use it in all his paintings, wouldn't he? I'm not trying to make\n",
      "fun of Eric Raymond here.  On the whole, his advice is good.  What\n",
      "he says about Lisp is pretty much the conventional wisdom.  But\n",
      "there is a contradiction in the conventional wisdom:  Lisp will\n",
      "make you a better programmer, and yet you won't use it.\n",
      "\n",
      "Why not?  Programming languages are just tools, after all.  If Lisp\n",
      "really does yield better programs, you should use it.  And if it\n",
      "doesn't, then who needs it?\n",
      "\n",
      "This is not just a theoretical question.  Software is a very\n",
      "competitive business, prone to natural monopolies.  A company that\n",
      "gets software written faster and better will, all other things\n",
      "being equal, put its competitors out of business.  And when you're\n",
      "starting a startup, you feel this very keenly.  Startups tend to\n",
      "be an all or nothing proposition.  You either get rich, or you get\n",
      "nothing.  In a startup, if you bet on the wrong technology, your\n",
      "competitors will crush you.\n",
      "\n",
      "Robert and I both knew Lisp well, and we couldn't see any reason\n",
      "not to trust our instincts and go with Lisp.  We knew that everyone\n",
      "else was writing their software in C++ or Perl.  But we also knew\n",
      "that that didn't mean anything.  If you chose technology that way,\n",
      "you'd be running Windows.  When you choose technology, you have to\n",
      "ignore what other people are doing, and consider only what will\n",
      "work the best.\n",
      "\n",
      "This is especially true in a startup.  In a big company, you can\n",
      "do what all the other big companies are doing.  But a startup can't\n",
      "do what all the other startups do.  I don't think a lot of people\n",
      "realize this, even in startups.\n",
      "\n",
      "The average big company grows at about ten percent a year.  So if\n",
      "you're running a big company and you do everything the way the\n",
      "average big company does it, you can expect to do as well as the\n",
      "average big company-- that is, to grow about ten percent a year.\n",
      "\n",
      "The same thing will happen if you're running a startup, of course.\n",
      "If you do everything the way the average startup does it, you should\n",
      "expect average performance.  The problem here is, average performance\n",
      "means that you'll go out of business.  The survival rate for startups\n",
      "is way less than fifty percent.  So if you're running a startup,\n",
      "you had better be doing something odd.  If not, you're in trouble.\n",
      "\n",
      "Back in 1995, we knew something that I don't think our competitors\n",
      "understood, and few understand even now:  when you're writing\n",
      "software that only has to run on your own servers, you can use\n",
      "any language you want.  When you're writing desktop software,\n",
      "there's a strong bias toward writing applications in the same\n",
      "language as the operating system.  Ten years ago, writing applications\n",
      "meant writing applications in C.  But with Web-based software,\n",
      "especially when you have the source code of both the language and\n",
      "the operating system, you can use whatever language you want.\n",
      "\n",
      "This new freedom is a double-edged sword, however.  Now that you\n",
      "can use any language, you have to think about which one to use.\n",
      "Companies that try to pretend nothing has changed risk finding that\n",
      "their competitors do not.\n",
      "\n",
      "If you can use any language, which do you use?  We chose Lisp.\n",
      "For one thing, it was obvious that rapid development would be\n",
      "important in this market.  We were all starting from scratch, so\n",
      "a company that could get new features done before its competitors\n",
      "would have a big advantage.  We knew Lisp was a really good language\n",
      "for writing software quickly, and server-based applications magnify\n",
      "the effect of rapid development, because you can release software\n",
      "the minute it's done.\n",
      "\n",
      "If other companies didn't want to use Lisp, so much the better.\n",
      "It might give us a technological edge, and we needed all the help\n",
      "we could get.  When we started Viaweb, we had no experience in\n",
      "business.  We didn't know anything about marketing, or hiring\n",
      "people, or raising money, or getting customers.  Neither of us had\n",
      "ever even had what you would call a real job.  The only thing we\n",
      "were good at was writing software.  We hoped that would save us.\n",
      "Any advantage we could get in the software department, we would\n",
      "take.\n",
      "\n",
      "So you could say that using Lisp was an experiment.  Our hypothesis\n",
      "was that if we wrote our software in Lisp, we'd be able to get\n",
      "features done faster than our competitors, and also to do things\n",
      "in our software that they couldn't do.  And because Lisp was so\n",
      "high-level, we wouldn't need a big development team, so our costs\n",
      "would be lower.  If this were so, we could offer a better product\n",
      "for less money, and still make a profit.  We would end up getting\n",
      "all the users, and our competitors would get none, and eventually\n",
      "go out of business.  That was what we hoped would happen, anyway.\n",
      "\n",
      "What were the results of this experiment?  Somewhat surprisingly,\n",
      "it worked.  We eventually had many competitors, on the order of\n",
      "twenty to thirty of them, but none of their software could compete\n",
      "with ours.  We had a wysiwyg online store builder that ran on the\n",
      "server and yet felt like a desktop application.  Our competitors\n",
      "had cgi scripts.  And we were always far ahead of them in features.\n",
      "Sometimes, in desperation, competitors would try to introduce\n",
      "features that we didn't have.  But with Lisp our development cycle\n",
      "was so fast that we could sometimes duplicate a new feature within\n",
      "a day or two of a competitor announcing it in a press release.  By\n",
      "the time journalists covering the press release got round to calling\n",
      "us, we would have the new feature too.\n",
      "\n",
      "It must have seemed to our competitors that we had some kind of\n",
      "secret weapon-- that we were decoding their Enigma traffic or\n",
      "something.  In fact we did have a secret weapon, but it was simpler\n",
      "than they realized.  No one was leaking news of their features to\n",
      "us.   We were just able to develop software faster than anyone\n",
      "thought possible.\n",
      "\n",
      "When I was about nine I happened to get hold of a copy of <i>The Day\n",
      "of the Jackal,</i> by Frederick Forsyth.  The main character is an\n",
      "assassin who is hired to kill the president of France.  The assassin\n",
      "has to get past the police to get up to an apartment that overlooks\n",
      "the president's route.  He walks right by them, dressed up as an\n",
      "old man on crutches, and they never suspect him.\n",
      "\n",
      "Our secret weapon was similar.  We wrote our software in a weird\n",
      "AI language, with a bizarre syntax full of parentheses.  For years\n",
      "it had annoyed me to hear Lisp described that way.  But now it\n",
      "worked to our advantage.  In business, there is nothing more valuable\n",
      "than a technical advantage your competitors don't understand.  In\n",
      "business, as in war, surprise is worth as much as force.\n",
      "\n",
      "And so, I'm a little embarrassed to say, I never said anything\n",
      "publicly about Lisp while we were working on Viaweb.  We never\n",
      "mentioned it to the press, and if you searched for Lisp on our Web\n",
      "site, all you'd find were the titles of two books in my bio.  This\n",
      "was no accident.  A startup should give its competitors as little\n",
      "information as possible.  If they didn't know what language our\n",
      "software was written in, or didn't care, I wanted to keep it that\n",
      "way.[2]\n",
      "\n",
      "The people who understood our technology best were the customers.\n",
      "They didn't care what language Viaweb was written in either, but\n",
      "they noticed that it worked really well.  It let them build great\n",
      "looking online stores literally in minutes.  And so, by word of\n",
      "mouth mostly, we got more and more users.  By the end of 1996 we\n",
      "had about 70 stores online.  At the end of 1997 we had 500.  Six\n",
      "months later, when Yahoo bought us, we had 1070 users.  Today, as\n",
      "Yahoo Store, this software continues to dominate its market.  It's\n",
      "one of the more profitable pieces of Yahoo, and the stores built\n",
      "with it are the foundation of Yahoo Shopping.  I left Yahoo in\n",
      "1999, so I don't know exactly how many users they have now, but\n",
      "the last I heard there were about 20,000.\n",
      "\n",
      "<!-- People sometimes ask me if Yahoo Store still uses Lisp.  Yes, all\n",
      "the Lisp code is still there.  Yahoo has server-side software\n",
      "written in all five of the languages Eric Raymond recommends to\n",
      "hackers.\n",
      "-->\n",
      "<b>The Blub Paradox</b>\n",
      "\n",
      "What's so great about Lisp?  And if Lisp is so great, why doesn't\n",
      "everyone use it?  These sound like rhetorical questions, but actually\n",
      "they have straightforward answers.  Lisp is so great not because\n",
      "of some magic quality visible only to devotees, but because it is\n",
      "simply the most powerful language available.  And the reason everyone\n",
      "doesn't use it is that programming languages are not merely\n",
      "technologies, but habits of mind as well, and nothing changes\n",
      "slower.  Of course, both these answers need explaining.\n",
      "\n",
      "I'll begin with a shockingly controversial statement:  programming\n",
      "languages vary in power.\n",
      "\n",
      "Few would dispute, at least, that high level languages are more\n",
      "powerful than machine language.  Most programmers today would agree\n",
      "that you do not, ordinarily, want to program in machine language.\n",
      "Instead, you should program in a high-level language, and have a\n",
      "compiler translate it into machine language for you.  This idea is\n",
      "even built into the hardware now: since the 1980s, instruction sets\n",
      "have been designed for compilers rather than human programmers.\n",
      "\n",
      "Everyone knows it's a mistake to write your whole program by hand\n",
      "in machine language.  What's less often understood is that there\n",
      "is a more general principle here: that if you have a choice of\n",
      "several languages, it is, all other things being equal, a mistake\n",
      "to program in anything but the most powerful one. [3]\n",
      "\n",
      "There are many exceptions to this rule.  If you're writing a program\n",
      "that has to work very closely with a program written in a certain\n",
      "language, it might be a good idea to write the new program in the\n",
      "same language.  If you're writing a program that only has to do\n",
      "something very simple, like number crunching or bit manipulation,\n",
      "you may as well use a less abstract language, especially since it\n",
      "may be slightly faster.  And if you're writing a short, throwaway\n",
      "program, you may be better off just using whatever language has\n",
      "the best library functions for the task.  But in general, for\n",
      "application software, you want to be using the most powerful\n",
      "(reasonably efficient) language you can get, and using anything\n",
      "else is a mistake, of exactly the same kind, though possibly in a\n",
      "lesser degree, as programming in machine language.\n",
      "\n",
      "You can see that machine language is very low level.  But, at least\n",
      "as a kind of social convention, high-level languages are often all\n",
      "treated as equivalent.  They're not.  Technically the term \"high-level\n",
      "language\" doesn't mean anything very definite.  There's no dividing\n",
      "line with machine languages on one side and all the high-level\n",
      "languages on the other.  Languages fall along a continuum [4] of\n",
      "abstractness, from the most powerful all the way down to machine\n",
      "languages, which themselves vary in power.\n",
      "\n",
      "Consider Cobol.  Cobol is a high-level language, in the sense that\n",
      "it gets compiled into machine language.  Would anyone seriously\n",
      "argue that Cobol is equivalent in power to, say, Python?  It's\n",
      "probably closer to machine language than Python.\n",
      "\n",
      "Or how about Perl 4?  Between Perl 4 and Perl 5, lexical closures\n",
      "got added to the language.  Most Perl hackers would agree that Perl\n",
      "5 is more powerful than Perl 4.  But once you've admitted that,\n",
      "you've admitted that one high level language can be more powerful\n",
      "than another.  And it follows inexorably that, except in special\n",
      "cases, you ought to use the most powerful you can get.\n",
      "\n",
      "This idea is rarely followed to its conclusion, though.  After a\n",
      "certain age, programmers rarely switch languages voluntarily.\n",
      "Whatever language people happen to be used to, they tend to consider\n",
      "just good enough.\n",
      "\n",
      "Programmers get very attached to their favorite languages, and I\n",
      "don't want to hurt anyone's feelings, so to explain this point I'm\n",
      "going to use a hypothetical language called Blub.  Blub falls right\n",
      "in the middle of the abstractness continuum.  It is not the most\n",
      "powerful language, but it is more powerful than Cobol or machine\n",
      "language.\n",
      "\n",
      "And in fact, our hypothetical Blub programmer wouldn't use either\n",
      "of them.  Of course he wouldn't program in machine language.  That's\n",
      "what compilers are for.  And as for Cobol, he doesn't know how\n",
      "anyone can get anything done with it.  It doesn't even have x (Blub\n",
      "feature of your choice).\n",
      "\n",
      "As long as our hypothetical Blub programmer is looking down the\n",
      "power continuum, he knows he's looking down.  Languages less powerful\n",
      "than Blub are obviously less powerful, because they're missing some\n",
      "feature he's used to.  But when our hypothetical Blub programmer\n",
      "looks in the other direction, up the power continuum, he doesn't\n",
      "realize he's looking up.  What he sees are merely weird languages.\n",
      "He probably considers them about equivalent in power to Blub, but\n",
      "with all this other hairy stuff thrown in as well.  Blub is good\n",
      "enough for him, because he thinks in Blub.\n",
      "\n",
      "When we switch to the point of view of a programmer using any of\n",
      "the languages higher up the power continuum, however, we find that\n",
      "he in turn looks down upon Blub.  How can you get anything done in\n",
      "Blub? It doesn't even have y.\n",
      "\n",
      "By induction, the only programmers in a position to see all the\n",
      "differences in power between the various languages are those who\n",
      "understand the most powerful one.  (This is probably what Eric\n",
      "Raymond meant about Lisp making you a better programmer.) You can't\n",
      "trust the opinions of the others, because of the Blub paradox:\n",
      "they're satisfied with whatever language they happen to use, because\n",
      "it dictates the way they think about programs.\n",
      "\n",
      "I know this from my own experience, as a high school kid writing\n",
      "programs in Basic.  That language didn't even support recursion.\n",
      "It's hard to imagine writing programs without using recursion, but\n",
      "I didn't miss it at the time.  I thought in Basic.  And I was a\n",
      "whiz at it.  Master of all I surveyed.\n",
      "\n",
      "The five languages that Eric Raymond recommends to hackers fall at\n",
      "various points on the power continuum.  Where they fall relative\n",
      "to one another is a sensitive topic.  What I will say is that I\n",
      "think Lisp is at the top.  And to support this claim I'll tell you\n",
      "about one of the things I find missing when I look at the other\n",
      "four languages.  How can you get anything done in them, I think,\n",
      "without macros? [5]\n",
      "\n",
      "Many languages have something called a macro.  But Lisp macros are\n",
      "unique.  And believe it or not, what they do is related to the\n",
      "parentheses.  The designers of Lisp didn't put all those parentheses\n",
      "in the language just to be different.  To the Blub programmer, Lisp\n",
      "code looks weird.  But those parentheses are there for a reason.\n",
      "They are the outward evidence of a fundamental difference between\n",
      "Lisp and other languages.\n",
      "\n",
      "Lisp code is made out of Lisp data objects.  And not in the trivial\n",
      "sense that the source files contain characters, and strings are\n",
      "one of the data types supported by the language.  Lisp code, after\n",
      "it's read by the parser, is made of data structures that you can\n",
      "traverse.\n",
      "\n",
      "If you understand how compilers work, what's really going on is\n",
      "not so much that Lisp has a strange syntax as that Lisp has no\n",
      "syntax.  You write programs in the parse trees that get generated\n",
      "within the compiler when other languages are parsed.  But these\n",
      "parse trees are fully accessible to your programs.  You can write\n",
      "programs that manipulate them.  In Lisp, these programs are called\n",
      "macros.  They are programs that write programs.\n",
      "\n",
      "Programs that write programs?  When would you ever want to do that?\n",
      "Not very often, if you think in Cobol.  All the time, if you think\n",
      "in Lisp.  It would be convenient here if I could give an example\n",
      "of a powerful macro, and say there! how about that?  But if I did,\n",
      "it would just look like gibberish to someone who didn't know Lisp;\n",
      "there isn't room here to explain everything you'd need to know to\n",
      "understand what it meant.  In \n",
      "<a href=\"acl.html\">Ansi Common Lisp</a> I tried to move\n",
      "things along as fast as I could, and even so I didn't get to macros\n",
      "until page 160.\n",
      "\n",
      "But I think I can give a kind of argument that might be convincing.\n",
      "The source code of the Viaweb editor was probably about 20-25%\n",
      "macros.  Macros are harder to write than ordinary Lisp functions,\n",
      "and it's considered to be bad style to use them when they're not\n",
      "necessary.  So every macro in that code is there because it has to\n",
      "be.  What that means is that at least 20-25% of the code in this\n",
      "program is doing things that you can't easily do in any other\n",
      "language.  However skeptical the Blub programmer might be about my\n",
      "claims for the mysterious powers of Lisp, this ought to make him\n",
      "curious.  We weren't writing this code for our own amusement.  We\n",
      "were a tiny startup, programming as hard as we could in order to\n",
      "put technical barriers between us and our competitors.\n",
      "\n",
      "A suspicious person might begin to wonder if there was some\n",
      "correlation here.  A big chunk of our code was doing things that\n",
      "are very hard to do in other languages.  The resulting software\n",
      "did things our competitors' software couldn't do.  Maybe there was\n",
      "some kind of connection.  I encourage you to follow that thread.\n",
      "There may be more to that old man hobbling along on his crutches\n",
      "than meets the eye.\n",
      "\n",
      "<b>Aikido for Startups</b>\n",
      "\n",
      "But I don't expect to convince anyone \n",
      "(<a href=\"http://www.trollope.org/scheme.html\">over 25</a>) \n",
      "to go out and learn\n",
      "Lisp.  The purpose of this article is not to change anyone's mind,\n",
      "but to reassure people already interested in using Lisp-- people\n",
      "who know that Lisp is a powerful language, but worry because it\n",
      "isn't widely used.  In a competitive situation, that's an advantage.\n",
      "Lisp's power is multiplied by the fact that your competitors don't\n",
      "get it.\n",
      "\n",
      "If you think of using Lisp in a startup, you shouldn't worry that\n",
      "it isn't widely understood.  You should hope that it stays that\n",
      "way. And it's likely to.  It's the nature of programming languages\n",
      "to make most people satisfied with whatever they currently use.\n",
      "Computer hardware changes so much faster than personal habits that\n",
      "programming practice is usually ten to twenty years behind the\n",
      "processor.  At places like MIT they were writing programs in\n",
      "high-level languages in the early 1960s, but many companies continued\n",
      "to write code in machine language well into the 1980s.  I bet a\n",
      "lot of people continued to write machine language until the processor,\n",
      "like a bartender eager to close up and go home, finally kicked them\n",
      "out by switching to a risc instruction set.\n",
      "\n",
      "Ordinarily technology changes fast.  But programming languages are\n",
      "different: programming languages are not just technology, but what\n",
      "programmers think in.  They're half technology and half religion.[6]\n",
      "And so the median language, meaning whatever language the median\n",
      "programmer uses, moves as slow as an iceberg.  Garbage collection,\n",
      "introduced by Lisp in about 1960, is now widely considered to be\n",
      "a good thing.  Runtime typing, ditto, is growing in popularity.\n",
      "Lexical closures, introduced by Lisp in the early 1970s, are now,\n",
      "just barely, on the radar screen.  Macros, introduced by Lisp in the\n",
      "mid 1960s, are still terra incognita.\n",
      "\n",
      "Obviously, the median language has enormous momentum.  I'm not\n",
      "proposing that you can fight this powerful force.  What I'm proposing\n",
      "is exactly the opposite: that, like a practitioner of Aikido, you\n",
      "can use it against your opponents.\n",
      "\n",
      "If you work for a big company, this may not be easy.  You will have\n",
      "a hard time convincing the pointy-haired boss to let you build\n",
      "things in Lisp, when he has just read in the paper that some other\n",
      "language is poised, like Ada was twenty years ago, to take over\n",
      "the world.  But if you work for a startup that doesn't have\n",
      "pointy-haired bosses yet, you can, like we did, turn the Blub\n",
      "paradox to your advantage:  you can use technology that your\n",
      "competitors, glued immovably to the median language, will never be\n",
      "able to match.\n",
      "\n",
      "If you ever do find yourself working for a startup, here's a handy\n",
      "tip for evaluating competitors.  Read their job listings.  Everything\n",
      "else on their site may be stock photos or the prose equivalent,\n",
      "but the job listings have to be specific about what they want, or\n",
      "they'll get the wrong candidates.\n",
      "\n",
      "During the years we worked on Viaweb I read a lot of job descriptions.\n",
      "A new competitor seemed to emerge out of the woodwork every month\n",
      "or so.  The first thing I would do, after checking to see if they\n",
      "had a live online demo, was look at their job listings.  After a\n",
      "couple years of this I could tell which companies to worry about\n",
      "and which not to.  The more of an IT flavor the job descriptions\n",
      "had, the less dangerous the company was.  The safest kind were the\n",
      "ones that wanted Oracle experience.  You never had to worry about\n",
      "those.  You were also safe if they said they wanted C++ or Java\n",
      "developers.  If they wanted Perl or Python programmers, that would\n",
      "be a bit frightening-- that's starting to sound like a company\n",
      "where the technical side, at least, is run by real hackers.  If I\n",
      "had ever seen a job posting looking for Lisp hackers, I would have\n",
      "been really worried.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<b>Notes</b>\n",
      "\n",
      "[1] Viaweb at first had two parts: the editor, written in Lisp,\n",
      "which people used to build their sites, and the ordering system,\n",
      "written in C, which handled orders.  The first version was mostly\n",
      "Lisp, because the ordering system was small.  Later we added two\n",
      "more modules, an image generator written in C, and a back-office\n",
      "manager written mostly in Perl.\n",
      "\n",
      "In January 2003, Yahoo released a new version of the editor \n",
      "written in C++ and Perl.  It's hard to say whether the program is no\n",
      "longer written in Lisp, though, because to translate this program\n",
      "into C++ they literally had to write a Lisp interpreter: the source\n",
      "files of all the page-generating templates are still, as far as I\n",
      "know,  Lisp code.  (See <a href=\"quotes.html\">Greenspun's Tenth Rule</a>.)\n",
      "\n",
      "[2] Robert Morris says that I didn't need to be secretive, because\n",
      "even if our competitors had known we were using Lisp, they wouldn't\n",
      "have understood why:  \"If they were that smart they'd already be\n",
      "programming in Lisp.\"\n",
      "\n",
      "[3] All languages are equally powerful in the sense of being Turing\n",
      "equivalent, but that's not the sense of the word programmers care\n",
      "about. (No one wants to program a Turing machine.)  The kind of\n",
      "power programmers care about may not be formally definable, but\n",
      "one way to explain it would be to say that it refers to features\n",
      "you could only get in the less powerful language by writing an\n",
      "interpreter for the more powerful language in it. If language A\n",
      "has an operator for removing spaces from strings and language B\n",
      "doesn't, that probably doesn't make A more powerful, because you\n",
      "can probably write a subroutine to do it in B.  But if A supports,\n",
      "say, recursion, and B doesn't, that's not likely to be something\n",
      "you can fix by writing library functions.\n",
      "\n",
      "[4] Note to nerds: or possibly a lattice, narrowing toward the top;\n",
      "it's not the shape that matters here but the idea that there is at\n",
      "least a partial order.\n",
      "\n",
      "[5] It is a bit misleading to treat macros as a separate feature.\n",
      "In practice their usefulness is greatly enhanced by other Lisp\n",
      "features like lexical closures and rest parameters.\n",
      "\n",
      "[6] As a result, comparisons of programming languages either take\n",
      "the form of religious wars or undergraduate textbooks so determinedly\n",
      "neutral that they're really works of anthropology.  People who\n",
      "value their peace, or want tenure, avoid the topic.  But the question\n",
      "is only half a religious one; there is something there worth\n",
      "studying, especially if you want to design new languages.\n",
      "<p align=justif>\n",
      "After a link to \n",
      "<a href=\"avg.html\">Beating the Averages</a> was posted on slashdot, \n",
      "some readers wanted to hear in more detail \n",
      "about the specific technical advantages we got from using\n",
      "Lisp in Viaweb.  For those who are interested,\n",
      "here are some excerpts from a talk I gave in April 2001 at\n",
      "BBN Labs in Cambridge, MA.\n",
      "1993\n",
      "<p align=justif>\n",
      "<i>(This essay is from the introduction to </i><a href=\"onlisp.html\">On Lisp</a>.<i>  The red text\n",
      "explains the origins of <a href=\"arc.html\">Arc</a>'s name.)</i>\n",
      "\n",
      "It's a long-standing principle of programming style that the functional\n",
      "elements of a program should not be too large.  If some component of a\n",
      "program grows beyond the stage where it's readily comprehensible,\n",
      "it becomes a mass of complexity which conceals errors as easily\n",
      "as a big city conceals fugitives.  Such software will be\n",
      "hard to read, hard to test, and hard to debug.\n",
      "\n",
      "In accordance with this principle, a large program must be divided\n",
      "into pieces, and the larger the program, the more it must be divided.\n",
      "How do you divide a program?  The traditional approach is\n",
      "called <i>top-down design:</i> you say \"the purpose of the\n",
      "program is to do these seven things, so I divide it into seven major\n",
      "subroutines.  The first subroutine has to do these four things, so\n",
      "it in turn will have four of its own subroutines,\" and so on.\n",
      "This process continues until the whole program has the right level\n",
      "of granularity-- each part large enough to do something substantial,\n",
      "but small enough to be understood as a single unit.\n",
      "\n",
      "Experienced Lisp programmers divide up their programs differently.\n",
      "As well as top-down design, they follow a principle which\n",
      "could be called <i>bottom-up design</i>-- changing the language\n",
      "to suit the problem.\n",
      "In Lisp, you don't just write your program down toward the language,\n",
      "you also build the language up toward your program.  As you're\n",
      "writing a program you may think \"I wish Lisp had such-and-such an\n",
      "operator.\" So you go and write it. Afterward\n",
      "you realize that using the new operator would simplify the design  \n",
      "of another part of the program, and so on.\n",
      "Language and program evolve together.\n",
      "Like the border between two warring states,\n",
      "the boundary between language and program is drawn and redrawn,\n",
      "until eventually it comes to rest along the mountains and rivers,\n",
      "the natural frontiers of your problem.\n",
      "In the end your program will look as if the language had been\n",
      "designed for it.\n",
      "And when language and\n",
      "program fit one another well, you end up with code which is\n",
      "clear, small, and efficient.\n",
      "\n",
      "<font color=#880000>\n",
      "It's worth emphasizing that bottom-up design doesn't mean\n",
      "just writing the same program in a different order.  When you\n",
      "work bottom-up, you usually end up with a different program.\n",
      "Instead of a single, monolithic program,\n",
      "you will get a larger language with more abstract operators,   \n",
      "and a smaller program written in it.  Instead of a lintel,\n",
      "you'll get an arch.\n",
      "</font>\n",
      "\n",
      "In typical code, once you abstract out the parts which are\n",
      "merely bookkeeping, what's left is much shorter;\n",
      "the higher you build up the language, the less distance you\n",
      "will have to travel from the top down to it.\n",
      "This brings several advantages:\n",
      "\n",
      "<ol>\n",
      "<li> By making the language do more of the work, bottom-up design\n",
      "yields programs which are smaller and more agile.  A shorter\n",
      "program doesn't have to be divided into so many components, and\n",
      "fewer components means programs which are easier to read or\n",
      "modify.  Fewer components also means fewer connections between   \n",
      "components, and thus less chance for errors there.  As\n",
      "industrial designers strive to reduce the number of moving parts\n",
      "in a machine, experienced Lisp programmers use bottom-up design\n",
      "to reduce the size and complexity of their programs.\n",
      "\n",
      "<li> Bottom-up design promotes code re-use.\n",
      "When you write two\n",
      "or more programs, many of the utilities you wrote for the first\n",
      "program will also be useful in the succeeding ones.  Once you've  \n",
      "acquired a large substrate of utilities, writing a new program can\n",
      "take only a fraction of the effort it would require if you had to \n",
      "start with raw Lisp.\n",
      "\n",
      "<li> Bottom-up design makes programs easier to read.\n",
      "<!--\n",
      "%It yields the same result as top-down design\n",
      "%with foresight---the foresight to arrange the branches near the\n",
      "%root of the tree so that among the leaves there is as little\n",
      "%duplication of effort as possible.\n",
      "-->\n",
      "An instance of this type\n",
      "of abstraction asks the reader to understand a general-purpose operator;\n",
      "an instance of functional abstraction asks the reader to understand\n",
      "a special-purpose subroutine. [1]\n",
      "\n",
      "<li> Because it causes you always to be on the lookout for patterns\n",
      "in your code, working bottom-up helps to clarify your ideas about\n",
      "the design of your program.  If two distant components of a program\n",
      "are similar in form, you'll be led to notice the similarity and\n",
      "perhaps to redesign the program in a simpler way.\n",
      "</ol>\n",
      "<p align=justif>\n",
      "Bottom-up design is possible to a certain degree in languages\n",
      "other than Lisp.  Whenever you see library functions,\n",
      "bottom-up design is happening.  However, Lisp gives you much broader\n",
      "powers in this department, and augmenting the language plays a\n",
      "proportionately larger role in Lisp style-- so much so that\n",
      "Lisp is not just a different language, but a whole different way\n",
      "of programming.\n",
      "\n",
      "It's true that this style of development is better suited to\n",
      "programs which can be written by small groups.  However, at the\n",
      "same time, it extends the limits of what can be done by a small\n",
      "group.  In <i>The Mythical Man-Month</i>,\n",
      "Frederick Brooks\n",
      "proposed that the productivity of a group of programmers\n",
      "does not grow linearly with its size.  As the size of the\n",
      "group increases, the productivity of individual programmers\n",
      "goes down.  The experience of Lisp programming  \n",
      "suggests a more cheerful way\n",
      "to phrase this law: as the size of the group decreases, the\n",
      "productivity of individual programmers goes up.\n",
      "A small group wins, relatively speaking, simply because it's\n",
      "smaller.  When a small group also takes advantage of the\n",
      "techniques that Lisp makes possible, it can \n",
      "<a href=\"avg.html\">win outright</a>.\n",
      "\n",
      "\n",
      "\n",
      "<b>New:</b> <a href=\"onlisptext.html\">Download On Lisp for Free</a>.\n",
      "\n",
      "\n",
      "\n",
      "<hr>\n",
      "\n",
      "\n",
      "[1] \"But no one can read\n",
      "the program without understanding all your new utilities.\"\n",
      "To see why such statements are usually mistaken,\n",
      "see Section 4.8.\n"
     ]
    }
   ],
   "source": [
    "print(essays[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Titles Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langsmith langchain-openai python-dotenv pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "We need to create a dataset that includes a list of indexes as the input and the expected titles in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_titles(essays: list[str]):\n",
    "    titles = []\n",
    "    for essay in essays:\n",
    "        title = essay.split(\"\\n\")[0]\n",
    "        titles.append(title)\n",
    "    return titles\n",
    "\n",
    "\n",
    "def create_titles_dataset(essays=essays, chunks=8):\n",
    "    examples = []\n",
    "    for index in range(0, len(essays), chunks):\n",
    "        # Current index and all indexes before it\n",
    "        indexes = [i for i in range(index)]\n",
    "        essays_to_parse = [essays[i] for i in indexes]\n",
    "\n",
    "        if not indexes:\n",
    "            continue\n",
    "\n",
    "        examples.append({\"inputs\": {\"indexes\": indexes}, \"outputs\": {\"titles\": parse_titles(essays=essays_to_parse)}})\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = create_titles_dataset()\n",
    "len(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': {'indexes': [0, 1, 2, 3, 4, 5, 6, 7]},\n",
       " 'outputs': {'titles': ['September 2017',\n",
       "   'January 2017',\n",
       "   'January 2017',\n",
       "   'November 2016',\n",
       "   'April 2016',\n",
       "   'January 2016',\n",
       "   'January 2016',\n",
       "   'January 2016']}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets upload them to a dataset in langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camronhaider/Documents/Dev/ContextLength-Experiment/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(name='Context Experiment - Titles', description='Experiment to test the ability of the LLM to recall titles from essays.', data_type=<DataType.kv: 'kv'>, id=UUID('682982f1-621b-46eb-b97e-46026f25bf45'), created_at=datetime.datetime(2024, 6, 16, 18, 23, 32, 612506, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 6, 16, 18, 23, 32, 612506, tzinfo=datetime.timezone.utc), example_count=20, session_count=28, last_session_start_time=datetime.datetime(2024, 6, 16, 20, 13, 56, 756473))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langsmith import Client\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Client()\n",
    "\n",
    "def upload_title_dateset():\n",
    "    dataset_name = \"Context Experiment - Titles\"\n",
    "\n",
    "    # Storing inputs in a dataset lets us\n",
    "    # run chains and LLMs over a shared set of examples.\n",
    "    if client.has_dataset(dataset_name=dataset_name):\n",
    "        dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "        return dataset\n",
    "    else:\n",
    "        dataset = client.create_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            description=\"Experiment to test the ability of the LLM to recall titles from essays.\",\n",
    "        )\n",
    "\n",
    "    for i, example in enumerate(examples):\n",
    "        client.create_example(\n",
    "            inputs=example[\"inputs\"],\n",
    "            outputs=example[\"outputs\"],\n",
    "            dataset_name=dataset.name,\n",
    "            metadata={\"index\": i}\n",
    "        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = upload_title_dateset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now lets write the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain_core langchain-openai langchain-google-genai matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class TitleSchema(BaseModel):\n",
    "    \"\"\"A list of ALL titles, including duplicates, in the order that they appear in the response.\"\"\"\n",
    "\n",
    "    titles: List[str] = Field(\n",
    "        description=\"A list of ALL titles, including duplicates, in the order that they appear in the response.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def llm_parse_titles(text: str, max_tokens=2000):\n",
    "    \"\"\"Use an LLM to parse the titles from the LLM output to an array\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.5,\n",
    "                     max_tokens=max_tokens).with_structured_output(TitleSchema)\n",
    "    system_prompt = \"\"\"The user was tasked with analyzing and writing a list of titles that they found in some essays. \\\n",
    "Your job is to parse the user's response and return a list of titles that they mentioned. Be very exact! The integrity of your \\\n",
    "response is very important. If you are off by a single character or line item, you will be penalized!!\"\"\"\n",
    "    response: TitleSchema = llm.invoke(\n",
    "        [SystemMessage(content=system_prompt), HumanMessage(content=text)])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets write the evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "\n",
    "def title_precision(root_run: Run, example: Example) -> dict:\n",
    "    \"\"\"The LLM's ability to only recall real titles from the expected list\"\"\"\n",
    "    output_titles: list[str] = root_run.outputs.get(\"titles\", [])\n",
    "    expected_titles: list[str] = example.outputs[\"titles\"]\n",
    "\n",
    "    if not output_titles:\n",
    "        return {\"score\": 0, \"key\": \"precision\", \"comment\": \"No output titles provided\"}\n",
    "\n",
    "    score = 0\n",
    "\n",
    "    expected_titles_copy = expected_titles.copy()\n",
    "\n",
    "    false_positives = []\n",
    "    for llm_title in output_titles:\n",
    "        if llm_title in expected_titles_copy:\n",
    "            score += 1\n",
    "            expected_titles_copy.remove(llm_title)\n",
    "        else:\n",
    "            false_positives.append(llm_title)\n",
    "\n",
    "    final_score = score / len(output_titles) if output_titles else 0.0\n",
    "    comment = f\"Titles not included in the example: {', '.join(false_positives)}\"\n",
    "    return {\"score\": final_score, \"key\": \"precision\", \"comment\": comment}\n",
    "\n",
    "\n",
    "def title_recall(root_run: Run, example: Example) -> dict:\n",
    "    \"\"\"The LLM's ability to recall all real titles from the expected list\"\"\"\n",
    "    output_titles: list[str] = root_run.outputs.get(\"titles\", [])\n",
    "    expected_titles: list[str] = example.outputs[\"titles\"]\n",
    "\n",
    "    total_expected_titles = len(expected_titles)\n",
    "    output_titles_copy = output_titles.copy()\n",
    "    score = 0\n",
    "    missed_titles = []\n",
    "\n",
    "    for expected_title in expected_titles:\n",
    "        if expected_title in output_titles_copy:\n",
    "            score += 1\n",
    "            # Remove the title to account for duplicates\n",
    "            output_titles_copy.remove(expected_title)\n",
    "        else:\n",
    "            missed_titles.append(expected_title)\n",
    "\n",
    "    final_score = score / total_expected_titles if total_expected_titles else 0.0\n",
    "    comment = f\"Missed titles from the expected list: {', '.join(missed_titles)}\"\n",
    "    return {\"score\": final_score, \"key\": \"recall\", \"comment\": comment}\n",
    "\n",
    "\n",
    "def title_order(root_run: Run, example: Example) -> dict:\n",
    "    \"\"\"The LLM's ability to order the titles correctly\"\"\"\n",
    "    output_titles: list[str] = root_run.outputs.get(\"titles\", [])\n",
    "    expected_titles: list[str] = example.outputs[\"titles\"]\n",
    "    score = 0\n",
    "    out_of_order_title = None\n",
    "\n",
    "    for index, title in enumerate(expected_titles):\n",
    "        try:\n",
    "            if title.lower() == output_titles[index].lower():\n",
    "                score += 1\n",
    "            else:\n",
    "                out_of_order_title = title\n",
    "                break\n",
    "        except:\n",
    "            out_of_order_title = title\n",
    "            break\n",
    "\n",
    "    final_score = score / len(expected_titles) if expected_titles else 0.0\n",
    "    comment = (\n",
    "        f\"First title out of order: {out_of_order_title}\"\n",
    "        if out_of_order_title\n",
    "        else \"All titles are in the correct order\"\n",
    "    )\n",
    "    return {\"score\": final_score, \"key\": \"order\", \"comment\": comment}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay this seems good. Lets put it all together into an eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Flash-base-14297ac1' at:\n",
      "https://smith.langchain.com/o/d967989d-4221-53db-b0a5-665b504acba2/datasets/682982f1-621b-46eb-b97e-46026f25bf45/compare?selectedSessions=d7a5e8b2-d01b-48ad-9079-7dc6a61934a5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 60.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n",
      "Predicting...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Predicting...\n",
      "Error: No content in response\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Gemini produced an empty response. Continuing with empty message\n",
      "Feedback: block_reason: OTHER\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No content in response\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langsmith import evaluate, EvaluationResult\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class TitlePredictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        prefix=\"Flash\",\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.prefix = prefix\n",
    "        self.results = None\n",
    "\n",
    "    def predict_titles(self, inputs: dict):\n",
    "        print(\"Predicting...\")\n",
    "        indexes: list[int] = inputs[\"indexes\"]\n",
    "\n",
    "        essays_for_context = [essays[i] for i in indexes]\n",
    "        essay_str = \"\\n\\n\".join(essays_for_context)\n",
    "\n",
    "        system_prompt = f\"\"\"You are a very thorough and detailed analyzer of Paul Graham essays. Your task it to analyze the \\\n",
    "provided essays and ONLY return a single list of titles in the order that they appear. You can tell which lines are titles because the \\\n",
    "contain ONLY a month and year followed by 2 new lines. For example: 'February 1993\\n\\n'. \n",
    "\n",
    "Return ONE numbered list of all of the titles you have found. \\\n",
    "You will be graded on precision and recall so be sure to include ALL of the titles that actually appear in the essays and in the correct order. \\\n",
    "Some duplicates are expected, just be sure to be as accurate as possible! \n",
    "\n",
    "\n",
    "<PAUL GRAHAM ESSAYS>\n",
    "{essay_str}\n",
    "</PAUL GRAHAM ESSAYS>\"\"\"\n",
    "\n",
    "        # Max tokens is indexes * 10\n",
    "        max_tokens = len(indexes) * 15\n",
    "\n",
    "        retries = 3\n",
    "        while retries > 0:\n",
    "\n",
    "            try:\n",
    "                llm = ChatGoogleGenerativeAI(\n",
    "                    model=self.model, temperature=1, max_output_tokens=max_tokens + 50,\n",
    "                )\n",
    "                response = llm.invoke(system_prompt)\n",
    "                if not response.content:\n",
    "                    raise Exception(\"No content in response\")\n",
    "\n",
    "                titles = llm_parse_titles(response.content, max_tokens)\n",
    "\n",
    "                if not titles.titles:\n",
    "                    raise Exception(\"No titles in response\")\n",
    "                print(f\"AI: {response.content}\")\n",
    "                return {\"response\": response.content, \"titles\": titles.titles}\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                retries -= 1\n",
    "                # Wait 15 seconds\n",
    "                time.sleep(60)\n",
    "        return {\"response\": \"\", \"titles\": []}\n",
    "\n",
    "    def evaluate(self, splits: list[str] = [\"Tiny\"], max_concurrency: int = 2, repetitions=2):\n",
    "        self.results = evaluate(\n",
    "            self.predict_titles,\n",
    "            data=client.list_examples(dataset_id=dataset.id, splits=splits),\n",
    "            evaluators=[title_precision, title_recall, title_order],\n",
    "            experiment_prefix=f\"{self.prefix}{f'-{splits[0]}' if splits else ''}\",\n",
    "            max_concurrency=max_concurrency,\n",
    "            num_repetitions=repetitions,\n",
    "        )\n",
    "        self.visualize_title_results()\n",
    "        return self.results\n",
    "\n",
    "    def visualize_title_results(self):\n",
    "        experiments = self.results._results\n",
    "        results = []\n",
    "        for experiment in experiments:\n",
    "            essay_count = len(experiment['example'].inputs[\"indexes\"])\n",
    "            metrics = [{\"key\": metric.key, \"score\": metric.score}\n",
    "                       for metric in experiment['evaluation_results']['results']]\n",
    "\n",
    "            results.append({\n",
    "                \"essay_count\": essay_count,\n",
    "                \"metrics\": metrics\n",
    "            })\n",
    "\n",
    "        # Sort by essay_count\n",
    "        results = sorted(results, key=lambda x: x['essay_count'])\n",
    "\n",
    "        # Extract the data for plotting\n",
    "        essay_counts = [result['essay_count'] for result in results]\n",
    "        precision_scores = [next(metric['score'] for metric in result['metrics']\n",
    "                                 if metric['key'] == 'precision') for result in results]\n",
    "        recall_scores = [next(metric['score'] for metric in result['metrics']\n",
    "                              if metric['key'] == 'recall') for result in results]\n",
    "        order_scores = [next(metric['score'] for metric in result['metrics']\n",
    "                             if metric['key'] == 'order') for result in results]\n",
    "\n",
    "        # Plot the data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        plt.plot(essay_counts, precision_scores, marker='o', label='Precision')\n",
    "        plt.plot(essay_counts, recall_scores, marker='o', label='Recall')\n",
    "        plt.plot(essay_counts, order_scores, marker='o', label='Order')\n",
    "\n",
    "        plt.xlabel('Number of Essays')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Accuracy Metrics Across Different Numbers of Essays')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "response = TitlePredictor().evaluate(splits=[\"base\"])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExperimentResults Flash-Base10-8669a81b>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
